{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 測試標註資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, \"by慶偉\")\n",
    "path = os.path.join(path, \"ic100-2\")\n",
    "annoabs = os.path.join(path, \"annotations\")\n",
    "imgabs = os.path.join(path, \"textdet_imgs\")\n",
    "\n",
    "data_type = [\"train\", \"test\"]\n",
    "for datatype in data_type:\n",
    "    annopath = os.path.join(annoabs, datatype)\n",
    "    imgpath = os.path.join(imgabs, datatype)\n",
    "    filelist = [filename for filename in os.listdir(imgpath) if filename.find(\".jpg\") != -1]\n",
    "\n",
    "    for filename in filelist:\n",
    "        \n",
    "        # txtfilename = filename.replace(\".jpg\", \".txt\")\n",
    "        imgfilename = \"3_0.jpg\"\n",
    "        txtfilename = imgfilename.replace(\".jpg\", \".txt\")\n",
    "\n",
    "        print(os.path.join(imgpath, imgfilename))\n",
    "        img = Image.open(os.path.join(imgpath, imgfilename))\n",
    "        img = np.array(img)\n",
    "\n",
    "        det_df = pd.read_csv(os.path.join(annopath, f\"gt_{txtfilename}\"), header=None)\n",
    "        print(imgfilename)\n",
    "        print(det_df)\n",
    "\n",
    "        det_df.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"txt\"]\n",
    "        print(det_df.columns)\n",
    "        print(det_df[\"0\"].iloc[1])\n",
    "        pts = [[det_df[\"0\"].iloc[1], det_df[\"1\"].iloc[1]],\n",
    "               [det_df[\"2\"].iloc[1], det_df[\"3\"].iloc[1]],\n",
    "               [det_df[\"4\"].iloc[1], det_df[\"5\"].iloc[1]],\n",
    "               [det_df[\"6\"].iloc[1], det_df[\"7\"].iloc[1]]]\n",
    "        pts = np.array(pts, np.int32)\n",
    "\n",
    "        cv2.polylines(img, [pts], isClosed=True, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "\n",
    "        print(pts)\n",
    "\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/imgs/CLAHE/0.jpg\"\n",
    "img = cv2.imread(path)\n",
    "plt.imshow(img)\n",
    "plt.title(img.shape)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "path2 = os.path.join(imgpath, imgfilename)\n",
    "img2 = Image.open(path2)\n",
    "img2 = np.array(img2)\n",
    "points = np.array([[480, 630], [1000, 630], [1000, 750], [480, 750]], np.int32)\n",
    "text = \"G2PWlW07\"\n",
    "\n",
    "cv2.polylines(img2, [points], isClosed=True, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.title(img2.shape)\n",
    "plt.show()\n",
    "\n",
    "c_img2 = cv2.rotate(img2, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "center = (img2.shape[1]//2, img2.shape[0]//2)\n",
    "angle = 90\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "\n",
    "rotated_pts = cv2.transform(np.array([points]), rotation_matrix).squeeze()\n",
    "rotated_pts = np.round(rotated_pts).astype(int)\n",
    "\n",
    "plt.imshow(c_img2)\n",
    "plt.title(c_img2.shape)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料增強 (翻轉)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "def rotate_imgs(srcimg, srcpts):\n",
    "    # dstimg = cv2.rotate(srcimg, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "    center = (srcimg.shape[1]//2, srcimg.shape[0]//2)\n",
    "    angle = 90\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "\n",
    "    rotated_pts = cv2.transform(np.array([srcpts]), rotation_matrix).squeeze()\n",
    "    rotated_pts = np.round(rotated_pts).astype(int)\n",
    "\n",
    "    ptsdf = pd.DataFrame(rotated_pts, columns=['X', 'Y'])\n",
    "\n",
    "    # # 打印原始DataFrame\n",
    "    # print(\"Original DataFrame:\")\n",
    "    # print(ptsdf)\n",
    "\n",
    "    # 将DataFrame放置在第一行\n",
    "    # print(ptsdf.values.flatten())\n",
    "    return ptsdf.values.flatten()\n",
    "\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, \"by慶偉\")\n",
    "path = os.path.join(path, \"dataset\")\n",
    "\n",
    "dataType = [\"imgs\", \"annotations\"]\n",
    "\n",
    "\n",
    "for anglestr in [0,90,180]:\n",
    "    filenameList = [filename for filename in os.listdir(os.path.join(path, dataType[0]))\n",
    "                    if filename.find(f\"_{str(anglestr)}.\")!=-1]\n",
    "    # print(filenameList)\n",
    "    for imgname in filenameList:\n",
    "        img = Image.open(os.path.join(os.path.join(path, dataType[0]), imgname))\n",
    "        img = np.array(img)\n",
    "\n",
    "        txtname = \"gt_\"+imgname.replace(\".jpg\", \".txt\")\n",
    "        df = pd.read_csv(os.path.join(os.path.join(path, dataType[1]), txtname), header=None)\n",
    "        df.columns = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"label\"]\n",
    "        # print(df)\n",
    "        # print(len(df))\n",
    "        newdf = df\n",
    "        for rdx in range(len(df)):\n",
    "            \n",
    "            aa = df.iloc[rdx][:-1].to_numpy()\n",
    "            pts = np.array([\n",
    "                [aa[0],aa[1]],\n",
    "                [aa[2],aa[3]],\n",
    "                [aa[4],aa[5]],\n",
    "                [aa[6],aa[7]]\n",
    "                ])\n",
    "\n",
    "            label = df.iloc[rdx][-1]\n",
    "            # print(pts)\n",
    "            \n",
    "            newpts = rotate_imgs(img, pts)\n",
    "            # print(newpts)\n",
    "\n",
    "            newdf.iloc[rdx, :-1] = newpts\n",
    "        # print(newdf)\n",
    "\n",
    "        dstimg = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        dstimgname = imgname.replace(f\"_{str(anglestr)}.jpg\", f\"_{str(anglestr+90)}.jpg\")\n",
    "        dsttxtname = txtname.replace(f\"_{str(anglestr)}.txt\", f\"_{str(anglestr+90)}.txt\")\n",
    "\n",
    "        print(os.path.join(os.path.join(path, dataType[0]), dstimgname))\n",
    "        print(os.path.join(os.path.join(path, dataType[1]), dsttxtname))\n",
    "        \n",
    "        # plt.subplot(1,2,1)\n",
    "        # plt.title(f\"{imgname} : {img.shape}\")\n",
    "        # plt.imshow(img)\n",
    "        # plt.subplot(1,2,2)\n",
    "        # plt.imshow(dstimg)\n",
    "        # plt.title(f\"{dstimgname} : {dstimg.shape}\")\n",
    "        # plt.show()\n",
    "        \n",
    "\n",
    "        dstimgpath = os.path.join(os.path.join(path, dataType[0]), dstimgname)\n",
    "        # os.remove(dstimgpath)\n",
    "\n",
    "        # 将 BGR 格式的图像转换为 RGB 格式\n",
    "        # img_rgb = cv2.cvtColor(dstimg, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 创建 PIL 图像对象\n",
    "        pil_img = Image.fromarray(dstimg)\n",
    "\n",
    "        # 保存图像\n",
    "        pil_img.save(dstimgpath)\n",
    "        # cv2.imwrite(dstimgpath, dstimg)\n",
    "        \n",
    "\n",
    "        newdf.to_csv(os.path.join(os.path.join(path, dataType[1]), dsttxtname),\n",
    "                    header=None, index=False)\n",
    "        # sys.exit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data split (train/test/val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, \"by慶偉\")\n",
    "srcpath = os.path.join(path, \"dataset\")\n",
    "srcimgpath = os.path.join(srcpath, \"imgs\")\n",
    "srctxtpath = os.path.join(srcpath, \"annotations\")\n",
    "\n",
    "dstpath = os.path.join(path, \"ic100-2\")\n",
    "\n",
    "imgfiles = [f\"{file}\" \n",
    "            for file in os.listdir(srcimgpath)]\n",
    "txtfiles = [f\"{file}\"\n",
    "            for file in os.listdir(srctxtpath)]\n",
    "print(len(imgfiles))\n",
    "print(len(txtfiles))\n",
    "df = pd.DataFrame({\"imgs\":imgfiles, \n",
    "                   \"annotations\":txtfiles})\n",
    "test_df = df.sample(frac=0.2)\n",
    "df = df.drop(test_df.index)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    for file in os.listdir(os.path.join(dstpath, f\"textdet_imgs/train/\")):\n",
    "        os.remove(os.path.join(dstpath, f\"textdet_imgs/train/{file}\"))\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    for file in os.listdir(os.path.join(dstpath, f\"textdet_imgs/test/\")):\n",
    "        os.remove(os.path.join(dstpath, f\"textdet_imgs/test/{file}\"))\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    for file in os.listdir(os.path.join(dstpath, f\"annotations/train/\")):\n",
    "        os.remove(os.path.join(dstpath, f\"annotations/train/{file}\"))\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    for file in os.listdir(os.path.join(dstpath, f\"annotations/test/\")):\n",
    "        os.remove(os.path.join(dstpath, f\"annotations/test/{file}\"))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "for idx in range(len(df)):\n",
    "\n",
    "    \n",
    "\n",
    "    src = os.path.join(srcimgpath, df[\"imgs\"].iloc[idx])\n",
    "    dst = os.path.join(dstpath, f\"textdet_imgs/train/{df['imgs'].iloc[idx]}\")\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "    src2 = os.path.join(srctxtpath, df[\"annotations\"].iloc[idx])\n",
    "    dst2 = os.path.join(dstpath, f\"annotations/train/{df['annotations'].iloc[idx]}\")\n",
    "    shutil.copyfile(src2, dst2)\n",
    "\n",
    "\n",
    "for idx in range(len(test_df)):\n",
    "\n",
    "    src = os.path.join(srcimgpath, test_df[\"imgs\"].iloc[idx])\n",
    "    dst = os.path.join(dstpath, f\"textdet_imgs/test/{test_df['imgs'].iloc[idx]}\")\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "    src2 = os.path.join(srctxtpath, df[\"annotations\"].iloc[idx])\n",
    "    dst2 = os.path.join(dstpath, f\"annotations/test/{test_df['annotations'].iloc[idx]}\")\n",
    "    shutil.copyfile(src2, dst2)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training loss curve (from training log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time, sleep\n",
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, \"mmocr\")\n",
    "path = os.path.join(path, \"tools\")\n",
    "path = os.path.join(path, \"data\")\n",
    "path = os.path.join(path, \"ic100-2\")\n",
    "path = os.path.join(path, \"20240315_121456\")\n",
    "path = os.path.join(path, \"vis_data\")\n",
    "jsonfile = [file for file in os.listdir(path) if file.find(\".json\") != -1 and file.find(\"scalar\") == -1][0]\n",
    "js_path = os.path.join(path, jsonfile)\n",
    "\n",
    "file = []\n",
    "try:\n",
    "    with open(js_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        # print(content)\n",
    "        lines = content.strip().split('\\n')\n",
    "\n",
    "\n",
    "        dictionaries = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            line.replace(\"NaN\", \"0\")\n",
    "            try:\n",
    "                # Use ast.literal_eval instead of eval for safer evaluation\n",
    "                dictionary = ast.literal_eval(line)\n",
    "                # Convert values to float, replacing '0' with 0\n",
    "                dictionary = {k: float(v) if v != '0' else 0 for k, v in dictionary.items()}\n",
    "                dictionaries.append(dictionary)\n",
    "            except (SyntaxError, ValueError) as e:\n",
    "                print(f\"Error evaluating line: {line}\\nError: {e}\")\n",
    "\n",
    "        # dictionaries = [eval(line) for line in lines]\n",
    "        # print(dictionaries)\n",
    "\n",
    "        # try:\n",
    "        #     dictionary = eval(content)\n",
    "        #     print(dictionary)\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error: {e}\")\n",
    "        # js = json.loads(content)\n",
    "        # file.append(js)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "    # Handle the exception or exit the program if necessary\n",
    "\n",
    "# Now, you can proceed with the normalization if js is defined successfully\n",
    "df = pd.DataFrame(dictionaries)\n",
    "\n",
    "# iterations = [entry[\"iter\"] for entry in dictionaries]\n",
    "iterations = (df[\"iter\"].values[:])\n",
    "# loss_values = [entry[\"loss\"] for entry in dictionaries]\n",
    "loss_values = df[\"loss\"].values[:]\n",
    "# loss_prob_values = [entry[\"loss_prob\"] for entry in dictionaries]\n",
    "loss_prob_values = df[\"loss_prob\"].values[:]\n",
    "\n",
    "# Plot the loss values against iterations\n",
    "plt.plot(iterations, loss_values, marker='o', linestyle='-', color='b', label='Loss')\n",
    "plt.plot(iterations, loss_prob_values, marker='s', linestyle='-', color='r', label='Loss Prob')\n",
    "\n",
    "plt.title('Loss Growth Over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "\n",
    "\n",
    "df.to_csv(\"ic_training_log.csv\", index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
