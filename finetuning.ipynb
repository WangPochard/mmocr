{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mmocr.apis import TextRecInferencer, TextDetInferencer, MMOCRInferencer\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from time import sleep\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# def image_rotate(image, position, angle):\n",
    "#     rotation_matrix = cv2.getRotationMatrix2D(position, angle, 1)\n",
    "#     # rotated_image = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "#     # rotated_image = cv2.transpose(image)\n",
    "#     rotated_image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "#     rotated_position = np.dot(rotation_matrix[:, :2], np.array(position)) + rotation_matrix[:, 2]\n",
    "\n",
    "#     h, w = rotated_image.shape[:2]\n",
    "#     image = rotated_image[int(rotated_position[1] - h/2):int(rotated_position[1] + h/2), int(rotated_position[0] - w/2):int(rotated_position[0] + w/2)]\n",
    "#     return image\n",
    "\n",
    "def image_rotate(image, position, angle):\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(position, angle, 1)\n",
    "    \n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "    rotated_position = np.dot(rotation_matrix[:, :2], np.array(position)) + rotation_matrix[:, 2]\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "def adjust_contrast_adaptive_histogram(image, clip_limit=2.0, tile_grid_size=(15, 15)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    adjusted_image = clahe.apply(image)\n",
    "    return adjusted_image\n",
    "\n",
    "def plotimg (img, filename):\n",
    "    plt.figure(figsize=(5, 10))\n",
    "    plt.imshow(img) #result['visualization'][0]\n",
    "    plt.title(filename)\n",
    "    plt.show()\n",
    "\n",
    "def mkdir (path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def draw_text_based_on_direction(image, points, text, font_scale=1, font_thickness=1, font_color=(255, 255, 255)):\n",
    "    # 座標轉換為OpenCV的格式\n",
    "    points = np.array(points, np.int32).reshape((-1, 1, 2))\n",
    "\n",
    "    # Polyline的長度\n",
    "    x_length = np.abs(points[:, 0, 0].max() - points[:, 0, 0].min())\n",
    "    y_length = np.abs(points[:, 0, 1].max() - points[:, 0, 1].min())\n",
    "\n",
    "    # 標註文字的位置和方向\n",
    "    # position = (points[:, 0, 0].mean(), points[:, 0, 1].mean())\n",
    "    direction = 'horizontal' if x_length >= y_length else 'vertical'\n",
    "\n",
    "    angle = 0 if direction == 'horizontal' else 90\n",
    "\n",
    "    cv2.drawContours(image, [points], -1, (0, 255, 0), 3)\n",
    "\n",
    "    if angle != 0:\n",
    "        # rotated_image = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "        # rotated_image = cv2.transpose(image)\n",
    "        rotated_image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        # 重新計算，旋轉標註文字位置\n",
    "        # rotated_position = np.dot(rotation_matrix[:, :2], np.array(position)) + rotation_matrix[:, 2]\n",
    "\n",
    "        # h, w = rotated_image.shape[:2]\n",
    "        # plt.imshow(rotated_image)\n",
    "        # plt.show()\n",
    "        # print(h, w)\n",
    "        image = rotated_image\n",
    "        # image = rotated_image[int(rotated_position[1] - h/2):int(rotated_position[1] + h/2), int(rotated_position[0] - w/2):int(rotated_position[0] + w/2)]\n",
    "        print(points.shape, type(points))\n",
    "        rotated_points = np.array([[point[0][1], (image.shape[0] - point[0][0])] for point in points] , np.int32).reshape((-1,1,2))\n",
    "        print(rotated_points.shape)\n",
    "        center_x = image.shape[1] // 2\n",
    "        center_y = image.shape[0] // 2\n",
    "\n",
    "        distances = np.linalg.norm(rotated_points - [center_x, center_y], axis=2)\n",
    "        closet_point_index = np.argmin(distances)\n",
    "\n",
    "        position = tuple(rotated_points[closet_point_index][0])\n",
    "        \n",
    "    else:\n",
    "        center_x = image.shape[1] // 2\n",
    "        center_y = image.shape[0] // 2\n",
    "\n",
    "        distances = np.linalg.norm(points - [center_x, center_y], axis=2)\n",
    "        closet_point_index = np.argmin(distances)\n",
    "\n",
    "        position = tuple(points[closet_point_index][0])\n",
    "        # rotated_position = position\n",
    "\n",
    "    cv2.putText(image, text, position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    if angle != 0:\n",
    "        # image = image_rotate(image, position, angle)\n",
    "        # image = image_rotate(image, position, angle)\n",
    "        # image = image_rotate(image, position, angle)\n",
    "        image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        # image = cv2.transpose(image)\n",
    "        # image = cv2.transpose(image)\n",
    "        # image = cv2.transpose(image)\n",
    "        # reverse_rotation_matrix = cv2.getRotationMatrix2D(rotated_position, -angle, 1)\n",
    "        # image = cv2.warpAffine(image, reverse_rotation_matrix, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return image\n",
    "\n",
    "# path = \"./data/icdar2015/imgs/training\"\n",
    "path = \"./data/imgs/CLAHE\" # equalization histogram image\n",
    "imgs = [file for file in os.listdir(path) if file.find(\".jpg\") != -1]\n",
    "for filename in imgs:\n",
    "    imgpath = os.path.join(path, filename)\n",
    "    img = cv2.imread(os.path.join(\"./data/imgs\", filename), cv2.IMREAD_COLOR) #imgpath\n",
    "    # checkpoint = \"./data/icdar/epoch_60.pth\"\n",
    "    # cfg_file = \"./data/icdar/dbnet_resnet50-dcnv2_fpnc_1200e_icdar2015.py\"\n",
    "    det_checkpoint = os.path.join(os.getcwd(), \"by慶偉/model/epoch_60.pth\")\n",
    "    det_file = os.path.join(os.getcwd(), \"by慶偉/model/dbnetpp_resnet50-dcnv2_fpnc_1200e_icdar2015_plusctw1500.py\")\n",
    "    \n",
    "    rec_checkpoint = \"abinet_union14m-cbf19742.pth\"\n",
    "    # rec_checkpoint = \"abinet_pretrain-45deac15.pth\"\n",
    "    rec_file = os.path.join(os.getcwd(), \"mmocr/configs/textrecog/abinet/abinet-vision_10e_union14m.py\")\n",
    "    # rec_file = os.path.join(os.getcwd(), \"mmocr/configs/textrecog/abinet/abinet_20e_st-an_mj.py\")\n",
    "    model = MMOCRInferencer(det=det_file, det_weights=det_checkpoint, \n",
    "                            rec=rec_file, rec_weights=rec_checkpoint) \n",
    "\n",
    "    # infer = TextDetInferencer(cfg_file, checkpoint)\n",
    "\n",
    "\n",
    "\n",
    "    result = model(imgpath, return_vis=True)\n",
    "\n",
    "    texts = result['predictions'][0]['rec_texts']\n",
    "    polygons = result['predictions'][0]['det_polygons']\n",
    "    scores = result['predictions'][0]['rec_scores']\n",
    "    for idx, polygon in enumerate(polygons):\n",
    "        text = texts[idx]\n",
    "        \n",
    "        cnt1 = [int(value) for value in polygon]\n",
    "        cnt1 = np.array([cnt1[i:i+2] for i in range(0, len(cnt1), 2)])\n",
    "        area = cv2.contourArea(cnt1)\n",
    "\n",
    "        if (area > 10000 and len(text) > 2): #(scores[idx] > 0.5):\n",
    "        \n",
    "            # cv2.drawContours(img, [cnt1], -1, (0, 255, 0), 3)\n",
    "            \n",
    "            # Retrieve bounding box of cnt1\n",
    "            # x, y, w, h = cv2.boundingRect(cnt1)\n",
    "            # replace any '<UKN>'  as ''\n",
    "            text = text.replace('<UKN>', '').upper()\n",
    "            # puttext the text on x,y\n",
    "            img = draw_text_based_on_direction(img, cnt1, text, font_scale=5, font_thickness=10, font_color=(0, 255, 0))\n",
    "\n",
    "            # cv2.putText(img, text, (x-100, y), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 255, 0), 10, cv2.LINE_AA)\n",
    "\n",
    "        print(f\"result : {texts}\")\n",
    "        gc.collect()\n",
    "    if (filename.find(\"img\") == -1):\n",
    "        cv2.imwrite(f\"C:/Users/User/Desktop/C_VSCode/mmocr/data/imgs/dst/{filename}\", img)\n",
    "\n",
    "        # print(result['predictions'][0])\n",
    "        \n",
    "        # plt.figure(figsize=(5, 10))\n",
    "        # plt.imshow(img) #result['visualization'][0]\n",
    "        # plt.title(filename)\n",
    "        # plt.show()\n",
    "    \n",
    "    gc.collect()\n",
    "    # sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time, sleep\n",
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "path = os.path.join(path, \"mmocr\")\n",
    "path = os.path.join(path, \"tools\")\n",
    "path = os.path.join(path, \"data\")\n",
    "path = os.path.join(path, \"icdar2015\")\n",
    "path = os.path.join(path, \"20240308_143720\")\n",
    "path = os.path.join(path, \"vis_data\")\n",
    "jsonfile = [file for file in os.listdir(path) if file.find(\".json\") != -1 and file.find(\"scalar\") == -1][0]\n",
    "js_path = os.path.join(path, jsonfile)\n",
    "\n",
    "file = []\n",
    "try:\n",
    "    with open(js_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        # print(content)\n",
    "        lines = content.strip().split('\\n')\n",
    "\n",
    "\n",
    "        dictionaries = []\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            line.replace(\"NaN\", \"0\")\n",
    "            try:\n",
    "                # Use ast.literal_eval instead of eval for safer evaluation\n",
    "                dictionary = ast.literal_eval(line)\n",
    "                # Convert values to float, replacing '0' with 0\n",
    "                dictionary = {k: float(v) if v != '0' else 0 for k, v in dictionary.items()}\n",
    "                dictionaries.append(dictionary)\n",
    "            except (SyntaxError, ValueError) as e:\n",
    "                print(f\"Error evaluating line: {line}\\nError: {e}\")\n",
    "\n",
    "        # dictionaries = [eval(line) for line in lines]\n",
    "        # print(dictionaries)\n",
    "\n",
    "        # try:\n",
    "        #     dictionary = eval(content)\n",
    "        #     print(dictionary)\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error: {e}\")\n",
    "        # js = json.loads(content)\n",
    "        # file.append(js)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error decoding JSON: {e}\")\n",
    "    # Handle the exception or exit the program if necessary\n",
    "\n",
    "# Now, you can proceed with the normalization if js is defined successfully\n",
    "df = pd.DataFrame(dictionaries)\n",
    "\n",
    "# iterations = [entry[\"iter\"] for entry in dictionaries]\n",
    "iterations = (df[\"iter\"].values[:])\n",
    "# loss_values = [entry[\"loss\"] for entry in dictionaries]\n",
    "loss_values = df[\"loss\"].values[:]\n",
    "# loss_prob_values = [entry[\"loss_prob\"] for entry in dictionaries]\n",
    "loss_prob_values = df[\"loss_prob\"].values[:]\n",
    "\n",
    "# Plot the loss values against iterations\n",
    "plt.plot(iterations, loss_values, marker='o', linestyle='-', color='b', label='Loss')\n",
    "plt.plot(iterations, loss_prob_values, marker='s', linestyle='-', color='r', label='Loss Prob')\n",
    "\n",
    "plt.title('Loss Growth Over Iterations')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n",
    "\n",
    "\n",
    "df.to_csv(\"training_log.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mmocr fine tuning by icdar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmocr.apis import MMOCRInferencer\n",
    "import torch as tc\n",
    "\n",
    "\n",
    "\n",
    "ocr = MMOCRInferencer(det='DBNet', rec='CRNN')\n",
    "ocr('./icdar2015/ch4_training_images/img_1.jpg', show=False, print_result=True)\n",
    "# ocr('./dataset/0.bmp', show=False, print_result=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ddnet ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_base_ = [\n",
    "    '_base_dbnetpp_resnet50-dcnv2_fpnc.py',\n",
    "    '../_base_/pretrain_runtime.py',\n",
    "    '../_base_/datasets/synthtext.py',\n",
    "    '../_base_/schedules/schedule_sgd_100k.py',\n",
    "]\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', color_type='color_ignore_orientation'),\n",
    "    dict(\n",
    "        type='LoadOCRAnnotations',\n",
    "        with_bbox=True,\n",
    "        with_polygon=True,\n",
    "        with_label=True,\n",
    "    ),\n",
    "    dict(type='FixInvalidPolygon'),\n",
    "    dict(\n",
    "        type='TorchVisionWrapper',\n",
    "        op='ColorJitter',\n",
    "        brightness=32.0 / 255,\n",
    "        saturation=0.5),\n",
    "    dict(\n",
    "        type='ImgAugWrapper',\n",
    "        args=[['Fliplr', 0.5],\n",
    "              dict(cls='Affine', rotate=[-10, 10]), ['Resize', [0.5, 3.0]]]),\n",
    "    dict(type='RandomCrop', min_side_ratio=0.1),\n",
    "    dict(type='Resize', scale=(640, 640), keep_ratio=True),\n",
    "    dict(type='Pad', size=(640, 640)),\n",
    "    dict(\n",
    "        type='PackTextDetInputs',\n",
    "        meta_keys=('img_path', 'ori_shape', 'img_shape'))\n",
    "]\n",
    "\n",
    "synthtext_textdet_train = _base_.synthtext_textdet_train\n",
    "synthtext_textdet_train.pipeline = train_pipeline\n",
    "\n",
    "train_dataloader = dict(\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
    "    dataset=synthtext_textdet_train)\n",
    "\n",
    "auto_scale_lr = dict(base_batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fpn ResNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3mb4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=7, scale=1):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        # self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Top layer\n",
    "        self.toplayer = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=0)  # Reduce channels\n",
    "        self.toplayer_bn = nn.BatchNorm2d(256)\n",
    "        self.toplayer_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Smooth layers\n",
    "        self.smooth1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.smooth1_bn = nn.BatchNorm2d(256)\n",
    "        self.smooth1_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.smooth2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.smooth2_bn = nn.BatchNorm2d(256)\n",
    "        self.smooth2_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.smooth3 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.smooth3_bn = nn.BatchNorm2d(256)\n",
    "        self.smooth3_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Lateral layers\n",
    "        self.latlayer1 = nn.Conv2d(1024, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.latlayer1_bn = nn.BatchNorm2d(256)\n",
    "        self.latlayer1_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.latlayer2 = nn.Conv2d(512,  256, kernel_size=1, stride=1, padding=0)\n",
    "        self.latlayer2_bn = nn.BatchNorm2d(256)\n",
    "        self.latlayer2_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.latlayer3 = nn.Conv2d(256,  256, kernel_size=1, stride=1, padding=0)\n",
    "        self.latlayer3_bn = nn.BatchNorm2d(256)\n",
    "        self.latlayer3_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(1024, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(256, num_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.scale = scale\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _upsample(self, x, y, scale=1):\n",
    "        _, _, H, W = y.size()\n",
    "        return F.upsample(x, size=(H // scale, W // scale), mode='bilinear')\n",
    "\n",
    "    def _upsample_add(self, x, y):\n",
    "        _, _, H, W = y.size()\n",
    "        return F.upsample(x, size=(H, W), mode='bilinear') + y\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.conv1(h)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu1(h)\n",
    "        h = self.maxpool(h)\n",
    "\n",
    "        h = self.layer1(h)\n",
    "        c2 = h\n",
    "        h = self.layer2(h)\n",
    "        c3 = h\n",
    "        h = self.layer3(h)\n",
    "        c4 = h\n",
    "        h = self.layer4(h)\n",
    "        c5 = h\n",
    "\n",
    "        # Top-down\n",
    "        p5 = self.toplayer(c5)\n",
    "        p5 = self.toplayer_relu(self.toplayer_bn(p5))\n",
    "\n",
    "        c4 = self.latlayer1(c4)\n",
    "        c4 = self.latlayer1_relu(self.latlayer1_bn(c4))\n",
    "        p4 = self._upsample_add(p5, c4)\n",
    "        p4 = self.smooth1(p4)\n",
    "        p4 = self.smooth1_relu(self.smooth1_bn(p4))\n",
    "\n",
    "        c3 = self.latlayer2(c3)\n",
    "        c3 = self.latlayer2_relu(self.latlayer2_bn(c3))\n",
    "        p3 = self._upsample_add(p4, c3)\n",
    "        p3 = self.smooth2(p3)\n",
    "        p3 = self.smooth2_relu(self.smooth2_bn(p3))        \n",
    "\n",
    "        c2 = self.latlayer3(c2)\n",
    "        c2 = self.latlayer3_relu(self.latlayer3_bn(c2))\n",
    "        p2 = self._upsample_add(p3, c2)\n",
    "        p2 = self.smooth3(p2)\n",
    "        p2 = self.smooth3_relu(self.smooth3_bn(p2))\n",
    "\n",
    "        p3 = self._upsample(p3, p2)\n",
    "        p4 = self._upsample(p4, p2)\n",
    "        p5 = self._upsample(p5, p2)\n",
    "\n",
    "        out = torch.cat((p2, p3, p4, p5), 1)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(self.bn2(out))\n",
    "        out = self.conv3(out)\n",
    "        out = self._upsample(out, x, scale=self.scale)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_model = model_zoo.load_url(model_urls['resnet50'])\n",
    "        state = model.state_dict()\n",
    "        for key in state.keys():\n",
    "            if key in pretrained_model.keys():\n",
    "                state[key] = pretrained_model[key]\n",
    "        model.load_state_dict(state)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_model = model_zoo.load_url(model_urls['resnet101'])\n",
    "        state = model.state_dict()\n",
    "        for key in state.keys():\n",
    "            if key in pretrained_model.keys():\n",
    "                state[key] = pretrained_model[key]\n",
    "        model.load_state_dict(state)\n",
    "    return model\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_model = model_zoo.load_url(model_urls['resnet152'])\n",
    "        state = model.state_dict()\n",
    "        for key in state.keys():\n",
    "            if key in pretrained_model.keys():\n",
    "                state[key] = pretrained_model[key]\n",
    "        model.load_state_dict(state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 資料後處理 EqualHist (CLAHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def adjust_contrast_adaptive_histogram(image, clip_limit=2.0, tile_grid_size=(15, 15)):\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    adjusted_image = clahe.apply(image)\n",
    "    return adjusted_image\n",
    "\n",
    "srcpath = os.path.join(os.getcwd(), \"data/imgs\")\n",
    "dstpath = os.path.join(srcpath, \"CLAHE\")\n",
    "imgs = [file for file in os.listdir(srcpath) if file.find(\".jpg\") != -1]\n",
    "\n",
    "for filename in imgs:\n",
    "    # img = cv2.imread(os.path.join(srcpath, filename))\n",
    "    # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # dst = cv2.equalizeHist(gray)\n",
    "    # plt.imshow(dst)\n",
    "    # plt.show()\n",
    "    # sys.exit()\n",
    "    image_path = os.path.join(srcpath, filename)\n",
    "    original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load the image in grayscale\n",
    "\n",
    "    cv2.medianBlur(original_image, 21, original_image)\n",
    "\n",
    "    equalized_image = adjust_contrast_adaptive_histogram(original_image, 9, (7, 7))\n",
    "\n",
    "    equalized_image = cv2.bilateralFilter(equalized_image, 13, 75, 75)\n",
    "\n",
    "    # Apply histogram equalization\n",
    "    # equalized_image = cv2.equalizeHist(original_image)\n",
    "\n",
    "    # Convert the original and equalized images to RGB for display\n",
    "    original_rgb = cv2.cvtColor(original_image, cv2.COLOR_GRAY2RGB)\n",
    "    equalized_rgb = cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # adjusted_image = cv2.convertScaleAbs(equalized_rgb, alpha=0.7, beta=0)\n",
    "    if (filename.find(\"12.jpg\") != -1):\n",
    "        # Display the original and equalized images side by side\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('Original Image')\n",
    "        plt.imshow(original_rgb)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title('Equalized Image')\n",
    "        plt.imshow(equalized_rgb)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        # plt.imshow(adjusted_image)\n",
    "        # plt.show()\n",
    "\n",
    "    cv2.imwrite(os.path.join(dstpath, filename), equalized_rgb)\n",
    "    # cv2.imwrite(os.path.join(dstpath, filename), equalized_rgb)\n",
    "    # cv2.imwrite(os.path.join(os.path.join(dstpath, \"constrast\"), filename), adjusted_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoloseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
